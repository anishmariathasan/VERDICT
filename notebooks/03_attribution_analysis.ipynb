{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91885a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "from utils import load_config, set_seed\n",
    "from models import MAIRA2Model\n",
    "from attribution import (\n",
    "    CoIBAForLVLM,\n",
    "    LayerAttribution,\n",
    "    TokenAttribution,\n",
    "    visualize_attribution,\n",
    "    plot_attribution_grid,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3eb3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(42)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018993e3",
   "metadata": {},
   "source": [
    "## 1. Load Model and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8222c2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load config\n",
    "config = load_config(project_root / \"configs\" / \"coiba_config.yaml\")\n",
    "\n",
    "# Load model (uncomment when ready)\n",
    "# model = MAIRA2Model.from_pretrained(\n",
    "#     checkpoint=config[\"model\"][\"checkpoint\"],\n",
    "#     device=device,\n",
    "#     load_in_8bit=True,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56d883c",
   "metadata": {},
   "source": [
    "## 2. Generate Attributions with CoIBA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8881ae1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_coiba_attribution(model, image, input_ids, target_token_idx):\n",
    "    \"\"\"Generate CoIBA attribution for a target token.\"\"\"\n",
    "    coiba = CoIBAForLVLM(model, config.get(\"coiba\", {}))\n",
    "    \n",
    "    attribution = coiba.generate_attribution(\n",
    "        image=image,\n",
    "        input_ids=input_ids,\n",
    "        target_token_idx=target_token_idx,\n",
    "        method=\"integrated_gradients\",\n",
    "        n_steps=50,\n",
    "    )\n",
    "    \n",
    "    return attribution\n",
    "\n",
    "# Example (uncomment when model loaded):\n",
    "# image_tensor = ...  # Load and preprocess image\n",
    "# input_ids = ...     # Tokenise prompt\n",
    "# attr = generate_coiba_attribution(model, image_tensor, input_ids, target_token_idx=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30638d7",
   "metadata": {},
   "source": [
    "## 3. Visualise Attribution Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca7c06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create synthetic example for demonstration\n",
    "dummy_image = np.random.rand(224, 224)\n",
    "dummy_attribution = np.random.rand(224, 224)\n",
    "\n",
    "# Centre the attribution to simulate focused region\n",
    "y, x = np.ogrid[:224, :224]\n",
    "centre_y, centre_x = 112, 112\n",
    "mask = np.exp(-((x - centre_x)**2 + (y - centre_y)**2) / (2 * 40**2))\n",
    "dummy_attribution = dummy_attribution * mask\n",
    "\n",
    "fig = visualize_attribution(\n",
    "    image=dummy_image,\n",
    "    attribution_map=dummy_attribution,\n",
    "    title=\"Sample Attribution Map\",\n",
    "    cmap=\"jet\",\n",
    "    alpha=0.5,\n",
    "    show=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c81b7c9",
   "metadata": {},
   "source": [
    "## 4. Compare Attribution Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d452a785",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_methods(model, image, input_ids, target_token_idx):\n",
    "    \"\"\"Compare different attribution methods.\"\"\"\n",
    "    methods = [\"integrated_gradients\", \"noise_tunnel\"]\n",
    "    results = {}\n",
    "    \n",
    "    coiba = CoIBAForLVLM(model)\n",
    "    \n",
    "    for method in methods:\n",
    "        attr = coiba.generate_attribution(\n",
    "            image=image,\n",
    "            input_ids=input_ids,\n",
    "            target_token_idx=target_token_idx,\n",
    "            method=method,\n",
    "            n_steps=20,\n",
    "        )\n",
    "        results[method] = attr\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Visualise comparison (placeholder)\n",
    "fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
    "axes[0].imshow(dummy_image, cmap=\"gray\")\n",
    "axes[0].set_title(\"Original Image\")\n",
    "axes[1].imshow(dummy_attribution, cmap=\"jet\")\n",
    "axes[1].set_title(\"Integrated Gradients\")\n",
    "axes[2].imshow(dummy_attribution * 0.8 + np.random.rand(224, 224) * 0.2, cmap=\"jet\")\n",
    "axes[2].set_title(\"SmoothGrad\")\n",
    "for ax in axes:\n",
    "    ax.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8644ed41",
   "metadata": {},
   "source": [
    "## 5. Token-Level Attribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ba083e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_token_importance(tokens, importance_scores):\n",
    "    \"\"\"Plot token importance scores.\"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(12, 4))\n",
    "    \n",
    "    colours = plt.cm.RdYlGn(importance_scores / importance_scores.max())\n",
    "    \n",
    "    ax.bar(range(len(tokens)), importance_scores, color=colours)\n",
    "    ax.set_xticks(range(len(tokens)))\n",
    "    ax.set_xticklabels(tokens, rotation=45, ha=\"right\")\n",
    "    ax.set_ylabel(\"Importance Score\")\n",
    "    ax.set_title(\"Token-Level Attribution\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example with dummy data\n",
    "tokens = [\"The\", \"heart\", \"is\", \"enlarged\", \"with\", \"cardiomegaly\"]\n",
    "scores = np.array([0.1, 0.8, 0.05, 0.9, 0.1, 0.95])\n",
    "plot_token_importance(tokens, scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c03b1c0",
   "metadata": {},
   "source": [
    "## 6. Next Steps\n",
    "\n",
    "- Apply to real MAIRA-2 outputs\n",
    "- Compare with ground truth anatomical regions\n",
    "- Quantify attribution quality metrics"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
