{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bef3596",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "from utils import load_config, set_seed\n",
    "from models import MAIRA2Model, MAIRA2Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af8fb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed for reproducibility\n",
    "set_seed(42)\n",
    "\n",
    "# Check device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22c0cf6",
   "metadata": {},
   "source": [
    "## 1. Load MAIRA-2 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd280a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration\n",
    "config = load_config(project_root / \"configs\" / \"maira2_config.yaml\")\n",
    "\n",
    "# Display model config\n",
    "print(\"Model configuration:\")\n",
    "for key, value in config[\"model\"].items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d7330e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model (requires GPU with sufficient memory)\n",
    "# Uncomment to load:\n",
    "\n",
    "# model = MAIRA2Model.from_pretrained(\n",
    "#     checkpoint=config[\"model\"][\"checkpoint\"],\n",
    "#     device=device,\n",
    "#     load_in_8bit=True,  # Use 8-bit quantisation to reduce memory\n",
    "# )\n",
    "# print(\"Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5634058",
   "metadata": {},
   "source": [
    "## 2. Run Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de9dee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_inference(model, image_path, prompt_type=\"findings\"):\n",
    "    \"\"\"Run inference on a single image.\"\"\"\n",
    "    # Load image\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    \n",
    "    # Generate report\n",
    "    output = model.generate(\n",
    "        images=image,\n",
    "        prompt_type=prompt_type,\n",
    "    )\n",
    "    \n",
    "    return output\n",
    "\n",
    "# Example usage (uncomment when model is loaded):\n",
    "# image_path = \"path/to/your/chest_xray.jpg\"\n",
    "# result = run_inference(model, image_path)\n",
    "# print(\"Generated Report:\")\n",
    "# print(result[\"generated_text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666000ac",
   "metadata": {},
   "source": [
    "## 3. Batch Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a288d5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_inference(model, image_paths, prompt_type=\"findings\"):\n",
    "    \"\"\"Run inference on multiple images.\"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for path in image_paths:\n",
    "        try:\n",
    "            result = run_inference(model, path, prompt_type)\n",
    "            results.append({\n",
    "                \"path\": str(path),\n",
    "                \"report\": result[\"generated_text\"],\n",
    "                \"success\": True,\n",
    "            })\n",
    "        except Exception as e:\n",
    "            results.append({\n",
    "                \"path\": str(path),\n",
    "                \"error\": str(e),\n",
    "                \"success\": False,\n",
    "            })\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01fb9ac1",
   "metadata": {},
   "source": [
    "## 4. Visual Question Answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc2071b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_question(model, image_path, question):\n",
    "    \"\"\"Ask a question about the image.\"\"\"\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    \n",
    "    output = model.generate(\n",
    "        images=image,\n",
    "        question=question,\n",
    "        prompt_type=\"vqa\",\n",
    "    )\n",
    "    \n",
    "    return output[\"generated_text\"]\n",
    "\n",
    "# Example:\n",
    "# answer = ask_question(model, image_path, \"Is there cardiomegaly present?\")\n",
    "# print(f\"Answer: {answer}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
